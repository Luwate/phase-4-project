{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/luwate/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data \n",
    "df=pd.read_csv('Apple-Twitter-Sentiment-DFE.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "3               2162\n",
       "1               1219\n",
       "5                423\n",
       "not_relevant      82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3886 entries, 0 to 3885\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   _unit_id              3886 non-null   int64  \n",
      " 1   _golden               3886 non-null   bool   \n",
      " 2   _unit_state           3886 non-null   object \n",
      " 3   _trusted_judgments    3886 non-null   int64  \n",
      " 4   _last_judgment_at     3783 non-null   object \n",
      " 5   sentiment             3886 non-null   object \n",
      " 6   sentiment:confidence  3886 non-null   float64\n",
      " 7   date                  3886 non-null   object \n",
      " 8   id                    3886 non-null   float64\n",
      " 9   query                 3886 non-null   object \n",
      " 10  sentiment_gold        103 non-null    object \n",
      " 11  text                  3886 non-null   object \n",
      "dtypes: bool(1), float64(2), int64(2), object(7)\n",
      "memory usage: 337.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_unit_id                   0\n",
       "_golden                    0\n",
       "_unit_state                0\n",
       "_trusted_judgments         0\n",
       "_last_judgment_at        103\n",
       "sentiment                  0\n",
       "sentiment:confidence       0\n",
       "date                       0\n",
       "id                         0\n",
       "query                      0\n",
       "sentiment_gold          3783\n",
       "text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['_last_judgment_at', 'sentiment_gold'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3886 entries, 0 to 3885\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   _unit_id              3886 non-null   int64  \n",
      " 1   _golden               3886 non-null   bool   \n",
      " 2   _unit_state           3886 non-null   object \n",
      " 3   _trusted_judgments    3886 non-null   int64  \n",
      " 4   sentiment             3886 non-null   object \n",
      " 5   sentiment:confidence  3886 non-null   float64\n",
      " 6   date                  3886 non-null   object \n",
      " 7   id                    3886 non-null   float64\n",
      " 8   query                 3886 non-null   object \n",
      " 9   text                  3886 non-null   object \n",
      "dtypes: bool(1), float64(2), int64(2), object(5)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "        # Remove mentions\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        #text =  re.sub(r'@+', '', text)\n",
    "        # Remove hashtags\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "        #text =  re.sub(r'#+', '', text)\n",
    "        # Remove RT (retweet) indicator\n",
    "        text = re.sub(r'^RT\\s+', '', text)\n",
    "        # Remove multiple spaces and strip\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        #lowercase text\n",
    "        text = text.lower()\n",
    "        #Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to the 'text' column\n",
    "df_clean['text'] = df_clean['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3886 entries, 0 to 3885\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   _unit_id              3886 non-null   int64  \n",
      " 1   _golden               3886 non-null   bool   \n",
      " 2   _unit_state           3886 non-null   object \n",
      " 3   _trusted_judgments    3886 non-null   int64  \n",
      " 4   sentiment             3886 non-null   object \n",
      " 5   sentiment:confidence  3886 non-null   float64\n",
      " 6   date                  3886 non-null   object \n",
      " 7   id                    3886 non-null   float64\n",
      " 8   query                 3886 non-null   object \n",
      " 9   text                  3886 non-null   object \n",
      "dtypes: bool(1), float64(2), int64(2), object(5)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_unit_id                  int64\n",
      "_golden                    bool\n",
      "_unit_state              object\n",
      "_trusted_judgments        int64\n",
      "sentiment                object\n",
      "sentiment:confidence    float64\n",
      "date                     object\n",
      "id                      float64\n",
      "query                    object\n",
      "text                     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [_unit_id, _golden, _unit_state, _trusted_judgments, sentiment, sentiment:confidence, date, id, query, text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "0    #AAPL:The 10 best Steve Jobs emails ever...htt...\n",
      "1    RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...\n",
      "2    My cat only chews @apple cords. Such an #Apple...\n",
      "3    I agree with @jimcramer that the #IndividualIn...\n",
      "4         Nobody expects the Spanish Inquisition #AAPL\n",
      "Name: text, dtype: object\n",
      "After cleaning:\n",
      "0                   the 10 best steve jobs emails ever\n",
      "1      why aapl stock had a miniflash crash today aapl\n",
      "2                      my cat only chews cords such an\n",
      "3    i agree with that the should own not trade  it...\n",
      "4               nobody expects the spanish inquisition\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Before cleaning:\")\n",
    "print(df['text'].head())\n",
    "print(\"\\\n",
    "After cleaning:\")\n",
    "print(df_clean['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the bestdesigned in the world according to'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['text'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My cat only chews @apple cords. Such an #AppleSnob.'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = RegexpTokenizer(pattern=r'(?u)\\w{3,}')\n",
    "df_clean['text'] = df_clean['text'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  [the, best, steve, jobs, emails, ever]\n",
       "1       [why, aapl, stock, had, miniflash, crash, toda...\n",
       "2                         [cat, only, chews, cords, such]\n",
       "3       [agree, with, that, the, should, own, not, tra...\n",
       "4            [nobody, expects, the, spanish, inquisition]\n",
       "                              ...                        \n",
       "3881    [via, apple, warming, social, media, apple, hi...\n",
       "3882               [there, avocado, emoji, may, ask, why]\n",
       "3883    [could, not, agree, more, between, and, only, ...\n",
       "3884    [iphone, photos, are, longer, downloading, aut...\n",
       "3885    [were, excited, named, app, store, best, 2014,...\n",
       "Name: text, Length: 3886, dtype: object"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "df_clean['text'] = df_clean['text'].apply(lambda x: [word for word in x if word not in stopwords_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       [best, steve, jobs, emails, ever]\n",
       "1            [aapl, stock, miniflash, crash, today, aapl]\n",
       "2                                     [cat, chews, cords]\n",
       "3       [agree, trade, extended, todays, pullback, goo...\n",
       "4                 [nobody, expects, spanish, inquisition]\n",
       "                              ...                        \n",
       "3881    [via, apple, warming, social, media, apple, hi...\n",
       "3882                           [avocado, emoji, may, ask]\n",
       "3883                [could, agree, great, things, happen]\n",
       "3884    [iphone, photos, longer, downloading, automati...\n",
       "3885    [excited, named, app, store, best, 2014, list,...\n",
       "Name: text, Length: 3886, dtype: object"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [best, steve, job, email, ever]\n",
       "1            [aapl, stock, miniflash, crash, today, aapl]\n",
       "2                                       [cat, chew, cord]\n",
       "3       [agre, trade, extend, today, pullback, good, see]\n",
       "4                     [nobodi, expect, spanish, inquisit]\n",
       "                              ...                        \n",
       "3881    [via, appl, warm, social, media, appl, hire, s...\n",
       "3882                           [avocado, emoji, may, ask]\n",
       "3883                  [could, agre, great, thing, happen]\n",
       "3884    [iphon, photo, longer, download, automat, lapt...\n",
       "3885    [excit, name, app, store, best, 2014, list, year]\n",
       "Name: text, Length: 3886, dtype: object"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmer\n",
    "stemmer = PorterStemmer()\n",
    "df_clean['text'].apply(lambda x: [stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['text'] = df_clean['text'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model \n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "analyser.polarity_scores(df_clean['text'][1])['compound']\n",
    "df_clean['scores'] = df_clean['text'].apply(lambda x: analyser.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "3               2162\n",
       "1               1219\n",
       "5                423\n",
       "not_relevant      82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.6369\n",
       "1      -0.4019\n",
       "2       0.0000\n",
       "3       0.6597\n",
       "4      -0.2960\n",
       "         ...  \n",
       "3881    0.1531\n",
       "3882    0.0000\n",
       "3883    0.7650\n",
       "3884    0.4019\n",
       "3885    0.7650\n",
       "Name: scores, Length: 3886, dtype: float64"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623495513</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>Mon Dec 01 19:30:03 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>best steve jobs emails ever</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623495514</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>Mon Dec 01 19:43:51 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>aapl stock miniflash crash today aapl</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>623495515</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mon Dec 01 19:50:28 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>cat chews cords</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>623495516</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>Mon Dec 01 20:26:34 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>agree trade extended todays pullback good see</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623495517</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>Mon Dec 01 20:29:33 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>nobody expects spanish inquisition</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>623499442</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7757</td>\n",
       "      <td>Tue Dec 09 22:08:53 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>via apple warming social media apple hiring so...</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>623499450</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>Tue Dec 09 22:18:27 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>avocado emoji may ask</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>623499486</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>Tue Dec 09 23:45:59 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>could agree great things happen</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>623499514</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>Wed Dec 10 00:48:10 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>iphone photos longer downloading automatically...</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>623517290</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8938</td>\n",
       "      <td>Tue Dec 09 09:01:25 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>excited named app store best 2014 list year</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3886 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _unit_id  _golden _unit_state  _trusted_judgments sentiment  \\\n",
       "0     623495513     True      golden                  10         3   \n",
       "1     623495514     True      golden                  12         3   \n",
       "2     623495515     True      golden                  10         3   \n",
       "3     623495516     True      golden                  17         3   \n",
       "4     623495517    False   finalized                   3         3   \n",
       "...         ...      ...         ...                 ...       ...   \n",
       "3881  623499442     True      golden                  13         3   \n",
       "3882  623499450     True      golden                  16         3   \n",
       "3883  623499486     True      golden                  14         5   \n",
       "3884  623499514     True      golden                  13         1   \n",
       "3885  623517290     True      golden                  17         5   \n",
       "\n",
       "      sentiment:confidence                            date            id  \\\n",
       "0                   0.6264  Mon Dec 01 19:30:03 +0000 2014  5.400000e+17   \n",
       "1                   0.8129  Mon Dec 01 19:43:51 +0000 2014  5.400000e+17   \n",
       "2                   1.0000  Mon Dec 01 19:50:28 +0000 2014  5.400000e+17   \n",
       "3                   0.5848  Mon Dec 01 20:26:34 +0000 2014  5.400000e+17   \n",
       "4                   0.6474  Mon Dec 01 20:29:33 +0000 2014  5.400000e+17   \n",
       "...                    ...                             ...           ...   \n",
       "3881                0.7757  Tue Dec 09 22:08:53 +0000 2014  5.420000e+17   \n",
       "3882                0.6225  Tue Dec 09 22:18:27 +0000 2014  5.420000e+17   \n",
       "3883                0.9347  Tue Dec 09 23:45:59 +0000 2014  5.420000e+17   \n",
       "3884                0.9230  Wed Dec 10 00:48:10 +0000 2014  5.420000e+17   \n",
       "3885                0.8938  Tue Dec 09 09:01:25 +0000 2014  5.420000e+17   \n",
       "\n",
       "                query                                               text  \\\n",
       "0     #AAPL OR @Apple                        best steve jobs emails ever   \n",
       "1     #AAPL OR @Apple              aapl stock miniflash crash today aapl   \n",
       "2     #AAPL OR @Apple                                    cat chews cords   \n",
       "3     #AAPL OR @Apple      agree trade extended todays pullback good see   \n",
       "4     #AAPL OR @Apple                 nobody expects spanish inquisition   \n",
       "...               ...                                                ...   \n",
       "3881  #AAPL OR @Apple  via apple warming social media apple hiring so...   \n",
       "3882  #AAPL OR @Apple                              avocado emoji may ask   \n",
       "3883  #AAPL OR @Apple                    could agree great things happen   \n",
       "3884  #AAPL OR @Apple  iphone photos longer downloading automatically...   \n",
       "3885  #AAPL OR @Apple        excited named app store best 2014 list year   \n",
       "\n",
       "      scores  \n",
       "0     0.6369  \n",
       "1    -0.4019  \n",
       "2     0.0000  \n",
       "3     0.6597  \n",
       "4    -0.2960  \n",
       "...      ...  \n",
       "3881  0.1531  \n",
       "3882  0.0000  \n",
       "3883  0.7650  \n",
       "3884  0.4019  \n",
       "3885  0.7650  \n",
       "\n",
       "[3886 rows x 11 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My iPhone 5's photos are no longer downloading automatically to my laptop when I sync it. @apple support is unhelpful. Any ideas?\""
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][3884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iphone photos longer downloading automatically laptop sync support unhelpful ideas'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['text'][3884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
